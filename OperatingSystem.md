操作系统

### 基本概念

内存溢出：简单地说内存溢出就是指**程序运行过程中申请的内存大于系统能够提供的内存，导致无法申请到足够的内存**，于是就发生了内存溢出。

内存泄漏：内存泄漏指程序运行过程中**分配内存给临时变量，用完之后却没有被GC回收，始终占用着内存**，既不能被使用也不能分配给其他程序，于是就发生了内存泄漏。

#### 系统调用

进程在系统的运行分为两个级别：

- 用户态（user mode）：用户态进程可以访问用户的数据
- 系统态（kernel mode）：系统态进程可以访问任何资源

系统调用：操作系统提供给应用程序使用的接口，应用程序通过系统调用来请求获得操作系统内核的服务。

#### 中断和异常

中断：发生中断就意味着需要操作系统介入，由用户态转为核心态，开展管理工作。

中断的分类：

- 内中断/异常：中断信号来源于 CPU 内部
  - 陷阱：e.g. 系统调用
  - 故障：缺页
  - 中止：不可恢复的致命错误 e.g.整数/0
- 外中断：中断信号来源于 CPU 外部
  - 外设请求：I/O操作完成
  - 人工干预：用户强行中止程序

外中断的处理过程

1. 完成每个指令后，CPU需要检查是否有外部中断信号
2. 如果检测到中断信号，需要保存被中断进程的中间结果
3. 转换为核心态 执行中断处理程序

#### 并发 vs 并行

- 并行：并行是指两个或者多个事件在同一时刻发生。

  当一个CPU执行一个线程时，另一个CPU可以执行另一个线程，两个线程互不抢占CPU资源，可以同时进行。

- 并发：两个或多个事件在同一时间间隔内发生。

  如果系统只有一个CPU,则它根本不可能真正同时进行一个以上的线程，它只能把CPU运行时间划分成若干个时间段,再将时间 段分配给各个线程执行，在一个时间段的线程代码运行时，其它线程处于挂起状。

#### 同步 异步 阻塞 非阻塞

- 同步（Synchronous）
- 异步（Asynchronous）
- 阻塞（Blocking）
- 非阻塞（Nonblocking）

### 进程管理

#### 进程与线程

**进程**是资源分配的基本单位。进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。

**线程**是独立调度的基本单位。一个进程中可以有多个线程，它们共享进程资源。

QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。

###### 进程

最早的计算机只支持单道程序，引入进程之后，多道程序可以并行执行。操作系统为每个进程分配一个数据结构，称为PCB。进程实体由三部分组成：程序段、数据段、PCB。进程实体可以简称为进程。

- 程序段：执行的代码
- 数据段：程序运行时产生的运算数据
- PCB

进程是一个程序在CPU执行时锁发生的活动。进程是进程实体的运行过程，是系统资源分配的一个独立单位。

进程的组织方式

- 链接方式：操作系统持有几个不同状态的指针，比如执行指针指向运行状态的进程，就绪队列队列指向就绪状态的进程

  ![1611718468143](C:/Users/wenyu/AppData/Roaming/Typora/typora-user-images/1611718468143.png)

- 索引方式：指针指向索引表，索引表的每个表项指向处于当前状态的PCB，操作系统为不同进程状态的进程建立不同的数据索引表

###### 线程

在没有引用进程之前，操作系统各个程序只能串行。引入进程之后，程序可以并行执行，比如一边聊QQ 一边听音乐。但有些进程需要同时做很多事，所以引入了线程，增加并发度。

线程是一个基本的CPU执行单元，调度的基本单位。

线程的实现方法：

- 用户级线程：由应用程序通过线程库实现，线程切换在用户态下即可完成
- 内核级线程：线程的管理由操作系统内核完成，内核级线程是操作系统内核视角可以看的线程
- 两者结合：可以将n个用户级线程映射到m个内核级线程上。

多线程模型：由几个用户级线程映射到几个内核级线程的问题

- 多对一模型：多个用户线程映射到一个内核级线程。

  优点： 用户级线程的切换在用户态下即可完成，不需要切换到核心态

  缺点：当一个用户线程被阻塞欧虎，整个进程都被阻塞

- 一对一模型：一个用户级线程映射到一个内核级线程。

  优点：一个线程被阻塞后，别的线程还可以继续执行

  缺点：一个进程会占用多个内核级线程，切换线程需要由操作系统完成

- 多对多模型：n个用户级线程映射到m个内核级线程（n>=m）

**进程 vs 线程**

- 拥有资源：进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。
- 调度：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。
- 系统开销：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。
- 通信方面：线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。

**进程状态**

- 创建状态（new）：进程正在被创建

- 就绪状态（ready）：进程等待分配处理器

- 运行状态（running）：进程正在处理器上运行

- 阻塞状态（waiting）：进程正在等待某一事件而暂停运行，比如I/O完成或者收到信号

- 结束状态（terminated）：进程完成执行。

  ![1611473857929](C:/Users/wenyu/AppData/Roaming/Typora/typora-user-images/1611473857929.png)

#### 进程控制块

操作系统为每个进程分配一个进程控制块（process control block），它包括与特定进程相关的消息：

- 进程状态：五个状态之一
- 程序计数器：进程要执行的下个指令的地址
- CPU 寄存器
- CPU 调度信息：调度优先级、调度参数
- 内存管理信息
- I/O 状态信息
- 记账信息：CPU 时间、实际使用时间、时间界限等

#### 上下文切换

CPU 中断当前进程，切换到另一个进程的过程，称为上下文切换。CPU 需要先保存当前进程的状态，然后装入执行的新进场的状态。

![1611507666759](C:/Users/wenyu/AppData/Roaming/Typora/typora-user-images/1611507666759.png)

#### 进程间通信

进程间通信：进程之间的信息交换。

为了保证进程安全，一个进程不能直接访问另一个进程的地址空间。

1. 共享内存
2. 消息传递
3. 管道通信

**共享存储**

操作系统为需要通信的两个进程分配一个共享空间。进程对共享空间的访问必须是互斥的。

共享存储分为两种：

- 基于数据结构的共享：共享空间内只能存放一种固定的数据结构
- 基于存储区的共享：共享空间内数据存放形式、位置都由进程控制

**管道通信**

管道是在内存中开辟的一个固定大小的缓冲区。

管道使用半双工通信，即在同一时间段内只能实现单向传输。如果需要双向通信，则需要设置两个管道。进程需要互斥地访问管道。

数据以字符流的形式写入管道。管道写满时，读进程可以将数据读走。当管道为空时，写进程可以继续写入。

数据一旦被读出，就从管道中删除。所以管道只允许一个读进程。

![1611715814801](C:/Users/wenyu/AppData/Roaming/Typora/typora-user-images/1611715814801.png)

**消息传递**

数据交换通过消息（message）为单位，操作系统提供发送消息/接受消息两个操作。

消息包括消息头和消息体。

![1611716027337](C:/Users/wenyu/AppData/Roaming/Typora/typora-user-images/1611716027337.png)

消息根据通信方式的不同，分为

- 直接通信方式：将消息加入接受进程的消息缓冲队列中。每个进程有一个消息缓冲队列。
- 间接通信方式：消息发送到中间实体中，也称信箱通信方式

### 进程同步

多道程序环境下，进程是并发执行的，不同进程间存在着不同的相互制约关系。为了协调进程之间的相互制约关系，达到资源共享和进程协作，避免进程之间的冲突，引入了进程同步的概念。

#### 临界资源

多个进程可以共享系统中的各种资源，但其中许多资源一次只能为一个进程所使用，我们把一次只允许一个进程使用的资源成为临界资源。

对临界资源的访问，必须互斥的进行。每个进程中，访问临界资源的那段代码成为临界区。

为了保证临界资源的正确使用，可以把临界资源的访问过程分为四个部分。

1） 进入区。为了进入临界区使用临界资源，在进入去要检查可否进入临界区。

2） 临界区。进程中访问临界资源的那段代码。

3） 退出区。将正在访问临界区的标志清除。

4） 剩余区。代码中的其余部分。

![1611582224033](C:/Users/wenyu/AppData/Roaming/Typora/typora-user-images/1611582224033.png)

#### Peterson 算法

Peterson 算法是基于软件上对于临界的解答。但是由于计算机指令执行有不同方式，Peterson 算法不能保证正确运行。

Peterson算法适用于两个进程在临界区与剩余区间交替执行。两个进程分别为 $P_0$ 和 $P_1$。算法需要共享两个数据项：1) ```int turn``` 2) ```boolean flag[2]```

```int turn``` 允许哪个进程进入临界区。```flag[2]``` 表示进程是否想进入临界区。

![1611582964028](C:/Users/wenyu/AppData/Roaming/Typora/typora-user-images/1611582964028.png)

#### 信号量

信号量（Semaphore）是一个整形变量。除了初始化之外，只能通过两个函数原子操作（不被分割不被中断执行的操作序列）访问。```wait()``` 操作，又称P 操作；和```signal()``` 又称V操作。

```
wait(S) {
    if(S <= 0) {
        ;
    }
    S --;
}
signal(S) {
    S ++;
}
```

信号量又可分为计数信号量和二进制信号量。二进制信号量的值只允许为0或1，而计数信号量的值域不受限制。二进制信号量可以解决多进程的临界区问题。n个进程共享一个变量mutex，并且信号量初始化值为1。计数信号量可以控制访问具有多个实例的某种资源。信号量初值为资源的个数。需要使用资源时，执行wait()。释放资源时，执行signal。

#### 经典同步问题

##### 生产者消费者

一组生产者进程和一组消费者进程共享一个初始为空、大小为n的缓冲区，只有缓冲区没满时，生产者才能把消息放入到缓冲区，否则必须等待；只有缓冲区不为空时，消费者才能从中取出消息，否则必须等待。由于缓冲区是临界资源，它只允许一个生产者放入消息，或一个消费者从中取出消息。

##### 读者-写者问题

一个文件可以被多个进程共享，允许多个 `Reader` 进程同时读这个文件，但不允许 `Wirter` 进程和其他 `Reader` 进程或 `Writer` 进程同时访问这个文件。所以读者-写者需要保证一个 `Writer` 进程必须与其他进程互斥地访问共享对象。

解决这个问题需要设置两个互斥信号量和一个整形变量：

- 互斥信号量 `wmutext`：实现 `Reader` 进程和 `Writer` 进程在读或写时的互斥；
- 整形变量 `readcount`：正在读的进程数目；
- 互斥信号量 `rmutext`：实现多个 `Reader` 进程对 `readcount` 变量的互斥访问；

```
semaphore rmutex = 1, wmutex = 1;
int readcount = 0;

void Reader() {
    while(TRUE) {
        wait(rmutex);
        if(readcount == 0) {
            wait(wmutex);
        }
        readcount++;
        signal(rmutex);
        // perform read opertaion
        wait(rmutex);
        readcount--;
        if(readcount == 0) {
            signal(wmutex);
        }
        signal(rmutex);
    }
}
void Writer() {
    while(TRUE) {
        wait(wmutex);
        // perform wirte opertaion
        signal(wmutex);
    }    
}

```

只要有一个 `Reader` 进程在读，便不允许 `Writer` 进程去写。所以，仅当 `readcount = 0`，表示没有 `Reader` 进程在读时，`Reader` 进程才需要执行 `wait(wmutex)` 操作/等待写进程，而 `readcount != 0` 时，表示有其他 `Reader` 进程在读，也就肯定没有 `Writer` 在写。同理，仅当 `readcount = 0` 时，才执行 `signal(wmutex)` 类似。

##### 哲学家就餐问题

一张圆桌上坐着五个哲学家，每两个哲学家之间的桌子上摆着一根筷子，一个哲学家一次只能拿一只筷子。当哲学家有两只筷子时，他才可以开始吃饭。

解决方法：每只筷子都用一个信号量来表示。一个哲学家通过执行wait()操作试图获取相应的筷子，他会通过执行signal()操作以释放相应的筷子。

共享数据为：semaphore chopstick[5];其中所有chopstick的元素初始化为1。

但这种方法可能导致死锁。

死锁的解决方法：

- 只有两只筷子都可用时才允许一个哲学家拿起它们（他必须在临界区内拿起两只筷子）；
- 使用非对称解决方法，即技术哲学家先拿起左边的筷子，接着拿起右边的筷子，而偶数哲学家先拿起右边的筷子，接着拿起左边的筷子。

### CPU 调度

对于单处理器系统，每个时间点只允许一个程序运行。CPU 调度通过在进程之间切换 CPU，使得 CPU 利用率最大化。

CPU 调度发生的条件：

- 当一个进程从运行状态切换到等待状态（比如等待 I/O 请求或者子进程的终止）
- 当一个进程从运行状态切换到就绪状态（中断发生）
- 当一个进程从等待状态切换到就绪状态（I/O 完成）
- 当一个进程终止

从调度机制上来讲，CPU 调度可以分为抢占式和协作式：

- 抢占式（preemptive）：允许调度程序根据某种规则，剥夺当前进程的调度资源，将其分配给其它进程
- 协作式（nonpreemptive）：一旦 CPU 分配给某个进程，该进程会一直使用 CPU 直到 进程终止或者切换到等待状态。

调度算法

批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

1. 先到先服务调度（First come first served）

   非抢占式的调度算法，先请求 CPU 的进程先分配到 CPU。

   FCFS 算法可以通过 FIFO 队列实现。当一个进程进入就绪队列，其 PCB 链接到队列尾部。当CPU 空闲时，CPU 会分配给队列头的进程。

   有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

2. 最短作业优先调度（shortest job first / SJF）

   非抢占式的调度算法，按估计运行时间最短的顺序进行调度。如果两个进程具有相同的最短运行时间，按照 FCFS 调度处理。

   长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

3. 最短剩余时间优先（shortest remaining time first）

   最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

1. 优先级调度（priority scheduling）

   每个进程都有一个优先级与其关联，具有最高优先级的进程会分配到 CPU。

   优先级调度可以是抢占式也可以是非抢占式。当一个进程到达就绪队列后，其优先级会和当前进程的优先级进行比较。如果新进程优先级高于当前进程，抢占式优先级调度会为其CPU。而非抢占式将新进场加入到就绪队列头部。

   优先级调度的一个问题是无穷阻塞或者饿死（starvation）。低优先级的进程会无穷等待 CPU。解决方法之一是老化（aging），逐渐增加在系统中等待时间长的进程的优先级。

2. 轮转法调度（round robin）

   将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

3. 多级队列调度（multilevel queue scheduling algorithm）

   将就绪队列分为多个独立队列，每个队列有自己的调度算法。

4. 多级反馈队列调度（multilevel feedback queue）

   该调度允许进程在队列之间移动。

#### 多处理器调度

多处理器系统具有多个并行工作的处理器，这些处理器共享计算机时钟，内存，总线，外围设备等。多处理器调度算法可分为：

- 非对称多处理（asymmetric multiprocessing）：一个处理器负责调度决定、I/O处理，其他处理器
- 对称多处理（symmetric multiprocessing）：每个处理器自我调度。

### 死锁

死锁状态发生在一组进程的每个进程都在等待一个事件，而这个事件只能由另一组进程引起。

死锁产生的必要条件：

1. 互斥条件：在一段时间内某资源仅为一个进程所占用。
2. 占有并等待：进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放。
3. 非剥夺：资源不能被抢占，资源只能在进程完成任务后释放
4. 循环等待：有一组等待进程$P_0, P_1, P_2... P_n$, $P_0$等待的资源被$P_1$占有， $P_1$等待的资源被$P_2$占有 ...

死锁问题可以用资源分配图表示。这个图由一个节点集合和一个边集合组成。如果每个资源类型有一个实例，那么有环意味着死锁。如果每个资源类型有多个实例，有环不意味着死锁。

死锁的处理方法：

- 死锁预防：出现死锁有4个必要条件，只要一个条件不成立，死锁就无法发生
- 死锁避免：通过获得进程申请资源的额外信息，动态检测资源分配状态。

### 内存管理

尽管内容容量也在不断增长，但是仍然不可能将所有用户进程和系统所需要的全部程序和数据全部放入主存中，所以操作系统必须将内存空间进行合理的化肥和有效的动态分配。这就是内存管理的概念。

内存是用于存放数据的硬件。程序执行前需要先放到内存中才能被 CPU 处理。内存中有一个一个小房间，每个房间就是一个**存储单位**。内存地址从0开始，每个地址对应一个存储单元。如果计算机按字节编址，也就是每个存储单元大小是1字节。如果按字编址，一个存储单元大小就是1个字。不同计算机字长不同。

内存分为程序段和数据段，程序段存放运算指令，数据段存放指令所需的数据。在指令中直接给出变量的实际地址，也就是**物理地址**。但是生成之前是不知道数据放在什么位置，所以一般用的是**逻辑地址**（相对地址）。

#### 代码的执行过程

编译：将代码翻译为机器语言，使用逻辑地址

链接：将编译后的代码和所需的库函数链接在一起，行程一个完整的模块。

- 静态链接：在程序运行之前，把目标模块和所需的库函数连接成一个完整的可执行文件。
- 装入时动态链接：在各模块装入内存时，边装入边链接
- 运行时动态链接：在程序需要运行该模块时，才对它进行链接。

装入：将程序装入内存中运行

- 绝对装入：如果编译时知道程序放到内存中哪个位置，编译程序将使用绝对地址。
- 静态重定位：在装入时对地址进行重定位，将逻辑地址转化为物理地址。在作业装入程序时，必须分配要求的全部内存空间。如果内存空间不足，则无法装入。 
- 动态重定位：装入程序把装入模块装入内存后，不会立即把逻辑地址转化为屋里地址，而是在程序将要执行的时候才转化。这个过程需要**重定位寄存器**的帮助，它用来存储装入模块存放的起始地址。

内存管理

1. 内存空间的分配和回收
2. 虚拟内存，对内存空间进行扩充
3. 地址转化，负责逻辑地址和物理地址的转换
4. 内存保护，保护在内存中运行的程序和数据正常运行，互不干扰
   1. 使用上、下限寄存器，分别存储进程的空间的上下限。当进程访问某个地址时，使用上下限进行【按断
   2. 使用重定位寄存器（进程的起始屋里地址）、界定位寄存器（进程的最大逻辑地址）

#### 内存空间的扩充

##### 覆盖技术

覆盖技术将程序分为多个**段**（模块），常用的段常驻内存，不常用的段在需要时装入内存。内存中分为一个**固定区**和多个**覆盖区**，需要常驻内存的段放在固定区，调入后就不再调出。不常用的段放在覆盖区，需要时调入内存。可以让不能被同时访问的程序段共享一个覆盖区。

缺点：需要程序员申明覆盖结构，增加用户变成负担

##### 交换技术

当内存空间紧张时，操作系统将内存中某些进程换出外存，把外存中需要执行的进程换入内存。

磁盘空间分为文件区和对换区。对换区占用磁盘空间的小部分，采用连续分配方式，I/O速度快。需要换出的进程就存放在对换区。

换出进程有多个影响因素：进程优先级、进程状态。

##### 虚拟存储

时间局部性：如果执行了程序的某条指令，不久后这条指令/数据可能被再次访问

空间局部性：如果程序访问了某个存储单元，不久后其附近的存储单元也可能被访问

应用局部性原理：把近期会频繁访问的数据放到更高速的存储器（内存）中，暂时用不到的数据放到更低速的存储器（外存）中。

在程序执行过程中，如果访问的信息不在内存时，操作系统将所需信息从外存调入内存，然后继续执行。如果当内存空间不足时，操作系统将内存中暂时用不到的信息换到外存。

用户似乎拥有一个比实际内存大得多的内存，这就是**虚拟内存**。 

虚拟内存的**最大容量**由操作系统的地质结构决定。e.g. 地址结构为32位，那么最大容量为2^32 = 4GB

虚拟内存的**实际容量** 为 min(内存+外存，CPU寻址范围)

![1611711930575](C:/Users/wenyu/AppData/Roaming/Typora/typora-user-images/1611711930575.png)

虚拟内存的实现建立在离散分配的内存管理方式基础上。

- 请求分页存储管理
- 请求分段存储管理
- 请求段页式存储管理

它与传统的离散分配的内存管理方式的不同是，增加了两个功能：

- 请求调页/段：当访问信息不在内存时，OS将信息从外存调入内存
- 页面置换/段置换：OS将用不到的信息换出外存

###### 请求分页管理机制

为了实现请求调页，操作系统需要知道每个页面是否调入内存，煤调入内存的页面在外存中的存放位置。

为了实现页面置换，操作系统需要通过某些指标决定换出哪个页面。如果页面没有修改过，就不需要浪费时间写会外存。有修改过的数据需要将外存中的旧数据重新覆盖。操作系统需要记录各个页面是否被修改过的信息。

![1611712922257](C:/Users/wenyu/AppData/Roaming/Typora/typora-user-images/1611712922257.png)

缺页中断

当访问的页面不在内存时，便产生一个缺页中断。由操作系统的缺页中断机构处理。缺页的进程阻塞，放入阻塞队列，调页完成时再将其唤醒，放回就绪队列。

缺页率 = 缺页中断次数 / 访问页面的次数

###### 页面置换算法

用于决定将哪个页面换出。

1. 最佳置换算法（OPT, optimal）

   选择在最长时间内不被访问的页面换出

   前提是知道进程接下来会访问页面的序列，但在实际中是无法得知的

2. 先进先出置换算法（FIFO）

   选择淘汰最早进入内存的页面。将页面根据调入的先后顺序排成一个队列，需要换出页面时选择头页面。

   belady异常：为进程分配的内存块数增大时，缺页次数不减反增的异常现象。

3. 最近最久未使用置换算法（LRU，least recently used）

   淘汰最近最久未使用的页面。在每个页面对应的页表项中，增加记录该页面从上次被访问以来经历的时间。需要淘汰页面时，选择时间最大的一项。

4. 时钟置换算法（clock）/ 最近未用算法

   简单时钟算法：

   为每个页面设置一个访问位。每个页面通过指针链接下一个页面。当页面被访问时，其访问位设为1。当需要淘汰一个页面时，检查页的访问位。如果0则换出，如果1，则重置为0。

   改进型的时钟算法：

   简单时钟算法只考虑一个页面最近是否被访问过。如果被淘汰的页面最近没有修改过，则不需要写回外存。改进型的时钟算法优先淘汰没有修改过的页面。

   增加一个修改位，修改位为0表示页面没有被修改过，修改位为1表示页面被修改过。

###### 页面分配策略

驻留集：请求分页存储中给进程分配的物理块的集合。

如果驻留集太小，会导致却也频繁。驻留集，导致多道程序并发度下降，资源利用率降低。

固定分配：操作系统为每个进程分配一组固定数目的物理块，在进程运行期间不再改变。

可变分配：为每个进程分配一定数目的物理块。在进程运行期间，根据情况适当修改。

#### 内存空间的分配与回收

连续分配方式：操作系统为进程分配一个连续的地址空间。

##### 单一连续分配

内存分为**系统区**和**用户区**。系统区存放操作系统相关数据，用户区存放用户进程数据。内存中只能有一道用户程序，它度战争用户区空间。

优点：实现简单，没有外部碎片

缺点：只适用单用户、单任务的操作系统，有**内部碎片**（操作系统分配给进程的内存区域中，如果有部分没有被利用）

##### 固定分区分配

将用户区划分为固定大小（或者不同大小）的分区，每个分区只装入一道作业。

操作系统需要维护一个**分区说明表**，记录每个分区的大小、以及是否被分配。

优点：无外部碎片

缺点：当进程太大，可能分区都不能满足需求，需要使用覆盖技术；产生内部碎片

##### 动态分区分配

在进程装入内存时，根据进程大小动态建立分区。

操作系统可以使用空闲分区表或者空闲分区链。空闲分区表记录内存中的空闲分区，包括分区大小、分区地址。空闲分区链是对每个空闲分区设置两个指针，指向前一个/后一个空闲分区。

动态分区分配算法负责选择一个空闲分区给新进程。

分区的分配与回收涉及空闲分区表进行修改。

动态分区分配算法：

- first fit
- best fit
- worst fit
- next fit

内部碎片：分配给进程的内存区域中，如果有部分没有利用上

外部碎片：内存中某些空闲分区由于太小而难以利用

非连续分配方式：为进程分配的是分散的内存空间。

##### 基本分页存储管理

把内存分为一个个相等的小分区。每个分区称为**页框**、**页帧**，页框号从0开始。然后再按分区大小把进程拆分成一个个小部分，称为**页**、**页面**，页号从0开始。操作系统以页框为单位为每个进程分配内存空间，进程的每个页面放入一个页框中，各个页面可以不连续存放。

为了知道进程的每个页面在内存中的存放位置，操作系统为每个进程建立一张**页表**。页表的每一项由页号和页框号组成。

逻辑地址转化为物理地址：

物理地址 = 页面地址 + 页面偏移量

页号 = 逻辑地址 / 页面长度

页内偏移量 = 逻辑地址 % 页面长度

页表寄存器，存放页表在内存这种的起始位置和页表长度。

**快表**，又称联想寄存器，是一种访问速度比内存快很多的缓冲寄存器。内存中的页表称为**慢表**。

**快表查询**

1. CPU 首先从快表中查询页号
2. 如果页号不存在，则从页表/慢表中查询
3. 将该页号对应的页表项插入快表

**两级页表**

单级页表的问题：

1. 页表必须连续存放，当页表很大时，需要占用很多页框

   解决方法：把单级页表分成一个个小块，每个块的大小是一个页。页表项由一级页号、二级页号、页内偏移量组成。

2. 进程在一段时间内只需要访问几个特定的页面

   解决方法：在需要访问页面时才把页面调入内存。在页表中加一个标志位，用于表示该页面是否已经调入内存。

   如果想访问的页面不在内存中，则发生**缺页中断**（内中断），需要将目标页面从外存调入内存。

##### 基本分段存储管理

进程按照程序**自身逻辑**划分为若干个段，每个段大小不一定相同，每段都有一个段名。操作系统以段为单位进行分配，每个段在内存中占据连续空间，各段之间可以不相邻。

操作系统为每个进程建议一张段表，记录各个段在内存中的存放位置。每个段对应一个段表项，包括段长和基址（该段在内存中的起始位置）。

分段 vs 分页

页是信息的物理单位，用户不知道进程分为几个段。页的大小固定，并且由系统决定。

段是信息的逻辑单位，分段对用户可见，用户编程时需要显式给出段名。段的长度不固定，取决于用户。

分段比分页更容易实现信息的共享。如果想让多个进程共享一个数据段，则让每个段指向内存中同一个段。

分页

优点：不会产生外部碎片，只会有少量的内部碎片

缺点：不方便按照逻辑模块实现内存分配

分段：

优点：按照逻辑模块实现内存分配

缺点：产生外部碎片

##### 段页式存储管理

将进程按照逻辑模块分段，然后再将各段分页。将内存分成大小相同的页帧/页框，进程的每个页面装入内存的一个页框中。

每个段对应一个段表项，每个段由段号、页表长度、页表存放块号组成。



